# build_embedding_index.py

import os
import faiss
import numpy as np
from sentence_transformers import SentenceTransformer
from langchain.text_splitter import RecursiveCharacterTextSplitter

import torch

# âœ… Step 1: åŠ è½½æ–‡æœ¬
with open("Hogwarts.txt", "r", encoding="utf-8") as f:
    raw_text = f.read()

# âœ… Step 2: æ–‡æœ¬åˆ‡åˆ†
splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=40)
chunks = splitter.split_text(raw_text)
print(f"ğŸ§© æ–‡æœ¬è¢«åˆ‡åˆ†ä¸º {len(chunks)} ä¸ªæ®µè½")

# âœ… Step 3: åŠ è½½ embedding æ¨¡å‹ï¼ˆGPU/CPU è‡ªé€‚åº”ï¼‰
device = "cuda" if torch.cuda.is_available() else "cpu"
# model = SentenceTransformer("all-MiniLM-L6-v2", device=device)
model = SentenceTransformer("/scratch/network/xz4883/all-MiniLM-L6-v2", device=device, local_files_only=True)
print(f"ğŸš€ ä½¿ç”¨è®¾å¤‡ï¼š{device}")

# âœ… Step 4: è®¡ç®— embedding
# embeddings = model.encode(chunks, show_progress_bar=True)
# âœ… Step 4: è®¡ç®— embeddingï¼ˆå¸¦ normalizeï¼‰
embeddings = model.encode(chunks, normalize_embeddings=True, show_progress_bar=True)

# âœ… Step 5: æ„å»º FAISS ç´¢å¼•
dimension = embeddings.shape[1]
index = faiss.IndexFlatL2(dimension)
index.add(np.array(embeddings))
print("âœ… å‘é‡ç´¢å¼•æ„å»ºå®Œæˆ")

# âœ… Step 6: ä¿å­˜æ–‡ä»¶
faiss.write_index(index, "Hogwarts_index.faiss")
with open("Hogwarts_chunks.npy", "wb") as f:
    np.save(f, chunks)

print("ğŸ“¦ å·²ä¿å­˜ Hogwarts_index.faiss ä¸ Hogwarts_chunks.npy")
